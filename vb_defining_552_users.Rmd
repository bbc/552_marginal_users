---
title: "vb_defining_552_users"
author: "VickyBanks"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
#rm(list = ls())
Sys.setenv(TZ="UTC")
knitr::opts_chunk$set(echo = TRUE)
options(java.parameters = "-Xmx64g")
library(tidyverse)
library(stringr)
library(rJava)
library(RJDBC)
library(tidyverse)
library(lubridate)
library(httr)
library(curl)
library(scales)
theme_set(theme_classic())
```

# Connect to the tables

```{r}
######### Get Redshift creds (local R) #########
options(java.parameters = "-Xmx64g")
driver <-JDBC("com.amazon.redshift.jdbc41.Driver","~/.redshiftTools/redshift-driver.jar",identifier.quote = "`")
my_aws_creds <-read.csv("~/Documents/Projects/DS/redshift_creds.csv",header = TRUE,stringsAsFactors = FALSE)
url <-paste0("jdbc:redshift://localhost:5439/redshiftdb?user=",my_aws_creds$user,"&password=",my_aws_creds$password)
conn <- dbConnect(driver, url)
dbGetQuery(conn,"select distinct brand_title, series_title from prez.scv_vmb ORDER BY RANDOM() limit 10;")


##get empty df with correct columns
compass.audience <- dbGetQuery(
  conn,
  paste0(
    "SELECT *
    FROM research_measurement_data.compass_audience_enriched
  WHERE start_datetime >= '2022-01-01' and start_datetime < '2023-01-01'
  AND stream_label ILIKE '%BBC%'LIMIT 1 ; "
  )
) %>% tail(-1)


start_date<-ymd('2022-01-01')
for(i in 1:12){
  print(start_date)

sql <- paste0(
  "SELECT *
    FROM research_measurement_data.compass_audience_enriched
  WHERE start_datetime >= '",start_date,"' and start_datetime < '",start_date %m+% months(1) ,"'
  AND stream_label ILIKE '%BBC%' ; "
)

temp<-dbGetQuery(conn, sql)
compass.audience <- compass.audience %>% rbind(temp)
rm(temp)
start_date<-start_date%m+% months(1)
}

compass.panel = dbGetQuery(conn, "SELECT * FROM research_measurement_data.compass_panelists_enriched WHERE update_date >= '2022-01-01' AND update_date < '2023-01-01'; ")

##get the colnames in a df
vars.audience = as.data.frame(colnames(compass.audience))
vars.panel = as.data.frame(colnames(compass.panel))

```
# Creating Overall VDH

This section creates a resp-week level table with time, dpw, and breadth at an overall level.

```{r check tables}

update.dates = 
  compass.panel %>%
  group_by(update_date) %>%
  tally() %>%
  collect()

stream.label = 
  compass.audience %>%
  group_by(stream_label) %>%
  tally() %>%
  collect()

```


```{r identify BBC}

compass.audience = 
  compass.audience %>%
  mutate(bbc.flag = case_when(  (grepl("BBC", stream_label, ignore.case = TRUE)==TRUE  &
                                grepl("YouTube", stream_label)==FALSE &
                                grepl("Facebook", stream_label)==FALSE &
                                grepl("Twitter", stream_label)==FALSE &
                                grepl("Instagram", stream_label)==FALSE &
                                grepl("BBCgoodfood.Com", stream_label)==FALSE &
                                stream_label!="BBC Good Food" &
                                stream_label!="BBC Good Food - App" &
                                stream_label!="Google AMP (BBC)") | 
                                (grepl("CBeebies", stream_label, ignore.case = TRUE)==TRUE & 
                                  grepl("YouTube", stream_label)==FALSE) ~ "BBC",
                                TRUE ~ "Other"))  %>%
  mutate(bbc.platform = case_when((data_type %in% c("LIVE", "VOSDAL", "TSV") & device == "TV" & grepl("Radio", stream_label)==FALSE)|
                                      (data_type=="VOD PLAYER" & stream_label!="BBC Podcasts - Online Player")| 
                                    stream_label %in% c("BBC iPlayer - App", "BBC iPlayer Home - Online Player", 
                                                        "BBC iPlayer Kids - App") ~ "Watching",
                                   (data_type %in% c("LIVE") & device == "RADIO" | grepl("Radio", stream_label)==TRUE) |
                                     grepl("BBC Sounds", stream_label)==TRUE |
                                    stream_label=="BBC Podcasts - Online Player" ~ "Listening",
                                   TRUE ~ "Explore")) %>%
  mutate(digital.platform = case_when(bbc.platform=="Watching" & 
                                        (data_type=="VOD PLAYER" | grepl("iPlayer", stream_label)==TRUE) & 
                                        stream_label!="BBC Podcasts - Online Player" ~ "iPlayer",
                                      bbc.platform=="Listening" & 
                                        (grepl("Online Player", stream_label, ignore.case = TRUE) == TRUE|
                                           grepl("Sounds", stream_label, ignore.case = TRUE) == TRUE) ~ "Sounds",
                                      bbc.platform == "Explore" & grepl("News", stream_label, ignore.case = TRUE)==TRUE ~ "News",
                                      bbc.platform == "Explore" & grepl("Sport", stream_label, ignore.case = TRUE)==TRUE ~ "Sport",
                                      bbc.platform == "Explore" ~ "Other BBC website / app",
                                         TRUE ~ "Non-digital platform"))


compass.audience$duration_secs<-as.numeric(compass.audience$duration_secs)
compass.panel$weight<-as.numeric(compass.panel$weight)

bbc.flag.check = 
  compass.audience %>%
  group_by(stream_label, bbc.flag) %>%
  tally() %>%
  collect()

bbc.platforms.check = 
  compass.audience %>%
  filter(bbc.flag=="BBC") %>%
  group_by(bbc.platform, stream_label, data_type, device) %>%
  tally() %>%
  collect()

bbc.digital.check = 
  compass.audience %>%
  filter(bbc.flag=="BBC") %>%
  group_by(digital.platform, stream_label) %>%
  tally() %>%
  collect()


iplayer.time.check = 
  compass.audience %>%
  filter(update_date>="2022-11-28" & update_date<="2022-12-26" & bbc.flag=="BBC" & 
           bbc.platform=="Watching" & digital.platform=="iPlayer") %>%
  left_join(compass.panel, by = c("update_date", "compass_id")) %>%
  group_by(update_date) %>%
  summarise(mins = sum(duration_secs*weight)/60) %>%
  collect()

iplayer.time.check

```


```{r Overall time}

time = 
  compass.audience %>%
  filter(bbc.flag=="BBC") %>%
  group_by(compass_id, update_date) %>%
  summarise(mins = sum(duration_secs, na.rm = TRUE)/60) %>%
  ungroup() 

time.product = 
  compass.audience %>%
  filter(bbc.flag=="BBC") %>%
  group_by(compass_id, update_date, digital.platform) %>%
  summarise(mins.product = sum(duration_secs)/60) %>%
  ungroup()



```


```{r Overall dpw}

min.hour = compass.audience %>%
  group_by(update_date) %>%
  summarise(min = min(start_datetime, na.rm = TRUE),
            max = max(start_datetime)) %>%
  ungroup() %>%
  mutate(min.hour = hour(min)) %>%
  select(update_date, min.hour) 

compass.audience = compass.audience %>%
  left_join(min.hour, by="update_date")

##Barb date quirks - the day goes from 6am to 6am
# update_date = 2022 - 12 - 19 00:00:00.000000,
# min = 2022 - 12 - 19 06:00:00.000000
# max = 2022 - 12 - 26 05:59:00.000000
# So that is a 7 day period
dpw = 
  compass.audience %>%
  filter(bbc.flag == "BBC")  %>%
  mutate(date = as.Date(start_datetime)) %>%
  mutate(Hour = hour(start_datetime)) %>%
  #mutate(date.m1 =  sql('DATEADD(day, -1, start_datetime)') ) %>% 
   mutate(date.m1 =  as.Date(start_datetime)-1 ) %>% ##previous day
  mutate(final.day = as.Date(update_date)+6) %>%
  ## if time 6am-midnight then day is that day
  ## if time less than 6am it's previous day
  mutate(day = case_when(Hour >= min.hour ~  day(as.Date(start_datetime) ),
                         Hour<min.hour ~ day(date.m1) )) %>%
  group_by(compass_id, update_date, day) %>%
  tally() %>%
  mutate(n = ifelse(n>=1,1,0)) %>%
  group_by(compass_id, update_date) %>%
  summarise(dpw = sum(n, na.rm = TRUE)) %>%
  ungroup()

dpw.product = 
  compass.audience %>%
  filter(bbc.flag == "BBC")  %>%
  mutate(date = as.Date(start_datetime)) %>%
  mutate(Hour = hour(start_datetime)) %>%
  #mutate(date.m1 =  sql('DATEADD(day, -1, start_datetime)') ) %>% 
   mutate(date.m1 =  as.Date(start_datetime)-1 ) %>% ##previous day
  mutate(final.day = as.Date(update_date)+6) %>%
  ## if time 6am-midnight then day is that day
  ## if time less than 6am it's previous day
  mutate(day = case_when(Hour >= min.hour ~  day(as.Date(start_datetime) ),
                         Hour<min.hour ~ day(date.m1) )) %>%
  group_by(compass_id, update_date, digital.platform, day) %>%
  tally() %>%
  mutate(n = ifelse(n>=1,1,0)) %>%
  group_by(compass_id, update_date, digital.platform) %>%
  summarise(dpw.product = sum(n, na.rm = TRUE)) %>%
  ungroup()

```

```{r Overall breadth}

# There are some mis-labellings between stream_label and device during the pandemic. In this case the device takes priority.

breadth = 
  compass.audience %>%
  filter(bbc.flag=="BBC") %>%
  group_by(compass_id, update_date, bbc.platform) %>%
  tally() %>%
  group_by(compass_id, update_date) %>%
  summarise(bbc.platforms = n()) %>%
  ungroup()

tv = 
  compass.audience %>%
  filter(bbc.flag=="BBC" & bbc.platform=="Watching") %>%
  group_by(compass_id, update_date) %>%
  tally() %>%
  ungroup() %>%
  mutate(bbc.tv = 1)

```

```{r Overall VDH}

vdh = 
  compass.panel %>%
  select(compass_id, update_date, weight, bbc_vfm) %>%
  left_join(time, by = c("compass_id", "update_date")) %>%
  left_join(dpw, by = c("compass_id", "update_date")) %>%
  left_join(breadth, by = c("compass_id", "update_date")) %>%
  left_join(tv, by = c("compass_id", "update_date")) %>%
  collect()

vdh[is.na(vdh)] = 0

results.vdh =
  vdh %>%
  mutate(overall.vdh = case_when(mins >= 5 * 60 & #5 hrs
                                   dpw >= 5 & #5 days
                                   bbc.platforms >= 2 & #2 modes
                                   bbc.tv == 1 ~ 1, #and includes tv
                                 TRUE ~ 0)) %>% ##then they meet 552 then 1
  group_by(update_date) %>%
  summarise(vdh = weighted.mean(x = overall.vdh, w = weight)) %>%
  ungroup()

```

```{r checks}
##per person vhd
met_vdh <-
  vdh %>%   mutate(overall.vdh = case_when(mins >= 5 * 60 & #5 hrs
                                             dpw >= 5 & #5 days
                                             bbc.platforms >= 2 & #2 modes
                                             bbc.tv == 1 ~ 1, #and includes tv
                                           TRUE ~ 0))  ##then they meet 552 then 1
write.csv(met_vdh %>% filter(compass_id %in% vdh$compass_id[1:3]), "test_vdh.csv")

met_vdh %>%  select(compass_id,update_date, overall.vdh) %>% filter(compass_id %in% vdh$compass_id[1:3]) %>% 
  ggplot(aes(x = update_date, y =overall.vdh, colour = compass_id))+
  geom_point()+
  facet_wrap(~compass_id, ncol = 1)+
  theme(legend.position="bottom")

```

### Analysis

```{r analysis1}
weeks_met_552<-
met_vdh %>% 
  group_by(compass_id) %>% 
  mutate(median_weight = median(weight)) %>% 
  group_by(compass_id, median_weight) %>%
  summarise(weeks_present = n(),
            weeks_met = sum(overall.vdh)) %>% 
  mutate(perc_present = round(100*weeks_met/weeks_present,0))%>% 
  filter(weeks_present>=13) %>%  ##only want to look at those who were there for more than 13 weeks
    mutate(perc_bands =
   cut(perc_present, breaks = c( 0,10, 20, 30, 40,50,60,70,80,90,100),
      labels = c('0-10','11-20','21-30','31-40','41-50','51-60','61-70','71-80','81-90','91-100'),
      include.lowest = TRUE) 
) 

weeks_met_552

## histogram based on panellists
ggplot(data=weeks_met_552, aes(x = perc_present))+
  geom_histogram(binwidth = 25)+
  labs(title = "Number of panellists who met 552 during the weeks present")+
  ylab("Number of panellists")+
  xlab("Percentage of weeks present")+
  scale_y_continuous(n.breaks = 10)
  


ggplot(data=weeks_met_552 , aes(y = perc_present))+
  geom_boxplot()+
  scale_y_continuous(n.breaks = 10)

```


```{r analysis2}

##how many people 
length(weeks_met_552$compass_id) #3792


perc_df<-
weeks_met_552 %>%
  group_by(perc_bands) %>% 
  summarise(panellists = n()) %>% 
left_join(
  weeks_met_552 %>%
  group_by(perc_bands) %>% 
  summarise(users = sum(median_weight) )
)
  
perc_df
## bar chart based on scaling people up to nat rep using their panelist weight
##the weight's median value were found as it's re-calcualted each week
perc_df %>% gather(key = metric, value = value, 2:3) %>% group_by(metric) %>% mutate(perc = paste0(round(100*value/sum(value),0),"%") ) %>% 
ggplot(aes(x = perc_bands, y = value, fill= metric ))+
  geom_bar(stat="identity", position=position_dodge())+
  facet_wrap(~metric, scale = "free", nrow = 2)+
  geom_text(aes(label=perc), vjust=1.6, color="white",
            position = position_dodge(0.9), size=3.5)+
  scale_y_continuous(labels = comma)

  
```


Users appear to be very habitual as they're either meeting 552 most weeks, or rarely. The opportunity audience isn't particularly large.

* Always - those above 80% (30% of users)
* Mostly - those from 50% to 80% (12% of users)
* Sometimes - those from 20% to 50% (17% of users)
* Rarely - those from 0-20% (41% of users)


```{r categorise}
weeks_met_552<-
weeks_met_552 %>% 
  mutate(usage_group = case_when(perc_present <=20 ~ 'rarely',
                                 perc_present >20 &   perc_present <=50 ~ 'sometimes',
                                 perc_present >50 &   perc_present <=80 ~ 'mostly',
                                 perc_present >80 ~ 'always' )   ) %>% 
  mutate(marginal = case_when(usage_group =='sometimes' | usage_group == 'mostly' ~ 1,
                              usage_group =='rarely' | usage_group == 'always' ~ 0
                              ))

```


```{r get demograpics}

## Users will have two ages over the year (as it's re-taken each week) and some change social grade 
## so clean the data to get the most common value for that user across the year
get_demographics<-function(demo){
  demographic<-
      dbGetQuery(
    conn,
    paste0("SELECT compass_id,", demo," 
    FROM research_measurement_data.compass_panelists_enriched
    WHERE update_date >= '2022-01-01' AND update_date < '2023-01-01'
    ORDER BY compass_id;"
  ) )
  
  print(demo)
  print(demographic %>% group_by(compass_id) %>% unique() %>% count() %>% group_by(n) %>% count())
  
  demographic<- demographic %>% group_by(compass_id, !!sym(demo)) %>% summarise(n =n()) %>% top_n(1) %>% select(-n)
  print(demographic %>% group_by(compass_id) %>% unique() %>% count() %>% group_by(n) %>% count())
  return(demographic)
}

age<-get_demographics("age")
gender<-get_demographics("gender")
nation<-get_demographics("nation")
social_grade<-get_demographics("social_grade_2")

age %>% group_by(compass_id) %>% count() %>% group_by(n) %>% count()

# get all demographics together
demographics<- age %>% left_join(gender)%>% left_join(nation)%>% left_join(social_grade)


weeks_met_552<-weeks_met_552 %>% left_join(demographics)
weeks_met_552<- weeks_met_552 %>% mutate(age_range = case_when(age <16 ~'under 16',
                                                               age >=16 & age <35 ~ '16-34',
                                                               age >=35 & age <55 ~'35-55',
                                                               age >=55 ~'55+'))
weeks_met_552
weeks_met_552$usage_group<-factor(weeks_met_552$usage_group, levels = c("rarely",'sometimes','mostly','always'))
weeks_met_552$gender<-factor(weeks_met_552$gender, levels = c("male",'female'))

nation_lookup<- data.frame(nation = c(1:4), nation_name = c("England","Wales","Scotland","NI")  )
weeks_met_552<-weeks_met_552 %>% mutate(nation = case_when(nation ==1 ~ 'England',
                                                           nation ==2 ~ 'Wales',
                                                           nation ==3 ~ 'Scotland',
                                                           nation ==4 ~ 'NI'
                                                           ) )
weeks_met_552<-weeks_met_552 %>% rename('social_grade' =social_grade_2) 
weeks_met_552<-weeks_met_552 %>% mutate(social_grade = case_when(social_grade ==1 ~ 'AB',
                                                           social_grade ==2 ~ 'C1',
                                                           social_grade ==3 ~ 'C2',
                                                           social_grade ==4 ~ 'DE',
                                                           social_grade ==5 ~ 'refused'
                                                           ) )


```

```{r marginal_gaphs}
group_totals<-weeks_met_552 %>% group_by(usage_group) %>% summarise(group_total = round(sum(median_weight),-6))
library(wesanderson)

make_demo_graph <- function(measure) {
  measure<-gsub(' ','_',tolower(measure))
  print(measure)
  
  df <-
    weeks_met_552 %>% group_by(usage_group, !!sym(measure)) %>% summarise(total = sum(median_weight)) %>%
    group_by(usage_group) %>% mutate(perc = paste0(round(100 * total / sum(total), 0), "%"))
  
  
  ggplot(data = df, aes(x = usage_group, y = total, fill = !!sym(measure))) +
    geom_bar(stat = "identity", position = position_stack()) +
    geom_text(aes(label = perc),
              position = position_stack(vjust = 0.5),
              colour = "black") +
    scale_y_continuous(labels = comma,
                       n.breaks = 10) +
    labs(title = "Frequency of users meeting the 552 definition") +
    ylab("Users") +
    theme(legend.position = "bottom",
          axis.title.x = element_blank()) +
    {if(measure == 'gender')scale_fill_manual(name = "Gender",values=wes_palette(n=3, name="GrandBudapest1"))
    else if (measure == 'age_range')scale_fill_manual(name = "Age Range",values = wes_palette(n = 3, name = "Darjeeling1"))
         else if (measure == 'social_grade')scale_fill_manual(name = "Social Grade",values = wes_palette(n = 5, name = "Darjeeling2"))
      }+
    geom_label(
      data = group_totals,
      aes(label = paste0(group_total / 1000000, " mil")),
      y = group_totals$group_total %>% max(),
      colour = "black",
      fill = "white"
    )
  
}


make_demo_graph('Age Range')
make_demo_graph('Gender')
make_demo_graph('Nation')
make_demo_graph('Social Grade')


```

What sections are people missing out by?

```{r missing_out}

met_vdh %>%  ungroup() %>% 
  filter(overall.vdh == 0) %>% 
  mutate(mins = ifelse( mins >= 5*60, 1, 0), ## if 5hrs then met target, else not met
         dpw = ifelse( dpw >= 5, 1, 0),
         platforms = ifelse( bbc.platforms >=2,1,0)
           ) %>% 
  select(compass_id, update_date, mins,dpw,platforms, bbc.tv) %>% 
  group_by(mins,dpw,platforms, bbc.tv) %>% 
  summarise(total = n()) %>% 
  arrange(desc(total)) %>% 
  ungroup() %>% 
  mutate(perc = round(100*total/sum(total),0)  )

```
What factor makes people miss out the most? (for all users)

* In 20% of cases they miss out on all metrics
* in 18% they miss on minutes but meet all others
* in 17% they miss on everything, but did watch tv
* in 15% of cases they miss on minutes and days per week
* in 13% of cases they miss on platforms but meet the other metrics


```{r marginals_missing_out}

met_vdh %>% 
  left_join(weeks_met_552 %>% select(compass_id, usage_group, marginal), by  = "compass_id") %>% 
  filter(marginal ==1) %>% 
  ungroup() %>% 
  filter(overall.vdh == 0) %>% 
  mutate(mins = ifelse( mins >= 5*60, 1, 0), ## if 5hrs then met target, else not met
         dpw = ifelse( dpw >= 5, 1, 0),
         platforms = ifelse( bbc.platforms >=2,1,0)
           ) %>% 
  select(compass_id, update_date, mins,dpw,platforms, bbc.tv) %>% 
  group_by(mins,dpw,platforms, bbc.tv) %>% 
  summarise(total = n()) %>% 
  arrange(desc(total)) %>% 
  ungroup() %>% 
  mutate(perc = round(100*total/sum(total),0)  )

```
What factor makes people miss out the most? (for all users)

* In 32% they miss on minutes but meet all others (rather than 18%)
* In 24% of cases they miss on platforms but meet the other metrics (rather than 13%)
* In 12% of cases they miss on minutes and days per week (rather than 15%)

This is quite different, but we are excluding everyone in the rarely group who just dont have a relationship with the BBC.









